general:
  train_data_size: 1  #-1 means unlimited games, where games are generated on the fly. In paper we use [1, 2, 10, 100, 500, -1], feel free to use any number.
  testset_path: "test_set"
  random_map: True  # If True, map size is sampled from [2, 12], if False, then map size is fixed to be 6.
  question_type: "existence"  # location, existence, attribute
  random_seed: 42  # the secret of deep learning.
  use_cuda: True  # disable this when running on machine without cuda

training:
  batch_size: 8
  max_episode: 10000
  target_net_update_frequency: 100  # sync target net with online net per this many epochs
  max_nb_steps_per_episode: 50  # after this many steps, a game is terminated
  optimizer:
    step_rule: 'AdamW'  # adam
    learning_rate: 0.00025
    clip_grad_norm: 5

evaluate:
    run_eval: False

checkpoint:
  save_checkpoint: True
  save_frequency: 1000  # episode
  experiment_tag: 'name_your_current_experiment_here'
  load_pretrained: False  # during test, enable this so that the agent load your pretrained model
  load_from_tag: 'your_previous_experiemnt_model'  # if you want to load from prev experiment

replay:
  discount_gamma: 0.9
  replay_memory_capacity: 500000  # adjust this depending on your RAM size
  update_per_k_game_steps: 20
  replay_batch_size: 64

epsilon_greedy:
  start_from_this_episode: 100
  epsilon_anneal_episodes: 1000  # -1 if not annealing
  epsilon_anneal_from: 1.0
  epsilon_anneal_to: 0.1

rewards:
  episodic_discovery: 0.5
  location: 1.0
  fact_finding: 1.0
  attribute: 1.0
  correct_answer: 10.0

model:
  action_length: 10
  word_embedding_size: 300
  conv_kernel: 5
  conv_stride: 3
  hidden_dim: 128
